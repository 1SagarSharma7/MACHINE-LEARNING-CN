## Gradient Descent ##

We will minimise the value of m and b.

### Learning Rate - alpha ###

m = m - (alpha) * slope

Learning rate should be kept small, to decrease the value of score with every iteration.

Code for gradient descent.

Learning Rate can also be set adaptive.

### Different Types ###

* Batch Gradient Descent
* Stochastic Gradient Descent
* Mini-Batch Gradient Descent

### Feature Scaling ###

All values of features placed between -1 to 1.

Explore SGD classifier of sklearn library.


Data Sets used : BOSTON :+1: 

:smiley: